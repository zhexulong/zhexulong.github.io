{"componentChunkName":"component---src-templates-blog-post-js","path":"/rk3588-prone/","result":{"data":{"site":{"siteMetadata":{"title":"且听龙吟"}},"markdownRemark":{"id":"8293b5a4-1d1e-5da0-bdf1-d580a1746b0c","excerpt":"模型剪枝 剪枝所需工具型代码 下面是相应python代码 剪枝过程 下面是相应python代码,只表示所需过程,仅供读者参考 微调(fine-tune)部分 下面是相应python代码,solver中实现了模型训练所需逻辑,暂无法提供源码 剪枝效果 发现剪枝效果如下表所示 模型类型 FLOPs Params…","html":"<h2 id=\"模型剪枝\" style=\"position:relative;\">模型剪枝<a href=\"#%E6%A8%A1%E5%9E%8B%E5%89%AA%E6%9E%9D\" aria-label=\"模型剪枝 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h2>\n<h3 id=\"剪枝所需工具型代码\" style=\"position:relative;\">剪枝所需工具型代码<a href=\"#%E5%89%AA%E6%9E%9D%E6%89%80%E9%9C%80%E5%B7%A5%E5%85%B7%E5%9E%8B%E4%BB%A3%E7%A0%81\" aria-label=\"剪枝所需工具型代码 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<p>下面是相应python代码</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> torch\r\n<span class=\"token keyword\">import</span> torch<span class=\"token punctuation\">.</span>nn <span class=\"token keyword\">as</span> nn\r\n\r\n\r\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Pruner</span><span class=\"token punctuation\">:</span>\r\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> net<span class=\"token punctuation\">,</span> flops_reg<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n        self<span class=\"token punctuation\">.</span>net <span class=\"token operator\">=</span> net<span class=\"token punctuation\">.</span><span class=\"token builtin\">eval</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n        <span class=\"token comment\"># Initialize stuff</span>\r\n        self<span class=\"token punctuation\">.</span>flops_reg <span class=\"token operator\">=</span> flops_reg\r\n        self<span class=\"token punctuation\">.</span>clear_rank<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n        self<span class=\"token punctuation\">.</span>clear_modules<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n        self<span class=\"token punctuation\">.</span>clear_cache<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n        <span class=\"token comment\"># Set hooks</span>\r\n        self<span class=\"token punctuation\">.</span>hook_handler <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>_register_hooks<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n\r\n    <span class=\"token keyword\">def</span> <span class=\"token function\">clear_rank</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n        self<span class=\"token punctuation\">.</span>ranks <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token punctuation\">}</span>  <span class=\"token comment\"># accumulates Taylor ranks for modules</span>\r\n        self<span class=\"token punctuation\">.</span>flops <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\r\n\r\n    <span class=\"token keyword\">def</span> <span class=\"token function\">clear_modules</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n        self<span class=\"token punctuation\">.</span>convs <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\r\n        self<span class=\"token punctuation\">.</span>BNs <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\r\n\r\n    <span class=\"token keyword\">def</span> <span class=\"token function\">clear_cache</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n        self<span class=\"token punctuation\">.</span>activation_maps <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\r\n        self<span class=\"token punctuation\">.</span>gradients <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\r\n\r\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward_hook_fn</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> module<span class=\"token punctuation\">,</span> <span class=\"token builtin\">input</span><span class=\"token punctuation\">,</span> output<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n        <span class=\"token triple-quoted-string string\">\"\"\" Stores the forward pass outputs (activation maps)\"\"\"</span>\r\n        self<span class=\"token punctuation\">.</span>activation_maps<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>output<span class=\"token punctuation\">.</span>clone<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>detach<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\n\r\n    <span class=\"token keyword\">def</span> <span class=\"token function\">backward_hook_fn</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> module<span class=\"token punctuation\">,</span> grad_in<span class=\"token punctuation\">,</span> grad_out<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n         <span class=\"token triple-quoted-string string\">\"\"\"Stores the gradients wrt outputs during backprop\"\"\"</span>\r\n         self<span class=\"token punctuation\">.</span>gradients<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>grad_out<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>clone<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>detach<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\n\r\n    <span class=\"token keyword\">def</span> <span class=\"token function\">_register_hooks</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n        handler_registry <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\r\n        <span class=\"token keyword\">for</span> name<span class=\"token punctuation\">,</span> module <span class=\"token keyword\">in</span> self<span class=\"token punctuation\">.</span>net<span class=\"token punctuation\">.</span>named_modules<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n            <span class=\"token keyword\">if</span> <span class=\"token builtin\">isinstance</span><span class=\"token punctuation\">(</span>module<span class=\"token punctuation\">,</span> nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n                <span class=\"token keyword\">if</span> name <span class=\"token operator\">!=</span> <span class=\"token string\">\"outc\"</span><span class=\"token punctuation\">:</span>  <span class=\"token comment\"># don't hook final conv module</span>\r\n                    handle_back <span class=\"token operator\">=</span> module<span class=\"token punctuation\">.</span>register_full_backward_hook<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>backward_hook_fn<span class=\"token punctuation\">)</span>\r\n                    handle_forw <span class=\"token operator\">=</span> module<span class=\"token punctuation\">.</span>register_forward_hook<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>forward_hook_fn<span class=\"token punctuation\">)</span>\r\n                    handler_registry<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>handle_back<span class=\"token punctuation\">)</span>\r\n                    handler_registry<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>handle_forw<span class=\"token punctuation\">)</span>\r\n                self<span class=\"token punctuation\">.</span>convs<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>module<span class=\"token punctuation\">)</span>\r\n            <span class=\"token keyword\">if</span> <span class=\"token builtin\">isinstance</span><span class=\"token punctuation\">(</span>module<span class=\"token punctuation\">,</span> nn<span class=\"token punctuation\">.</span>BatchNorm2d<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n                self<span class=\"token punctuation\">.</span>BNs<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>module<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># save corresponding BN layer</span>\r\n        <span class=\"token keyword\">return</span> handler_registry\r\n\r\n    <span class=\"token keyword\">def</span> <span class=\"token function\">compute_rank</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>  <span class=\"token comment\"># Compute ranks after each minibatch</span>\r\n        self<span class=\"token punctuation\">.</span>gradients<span class=\"token punctuation\">.</span>reverse<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n\r\n        <span class=\"token keyword\">for</span> layer<span class=\"token punctuation\">,</span> act <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>activation_maps<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n            taylor <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>act<span class=\"token operator\">*</span>self<span class=\"token punctuation\">.</span>gradients<span class=\"token punctuation\">[</span>layer<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>mean<span class=\"token punctuation\">(</span>dim<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">abs</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>mean<span class=\"token punctuation\">(</span>dim<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># C</span>\r\n\r\n            <span class=\"token keyword\">if</span> layer <span class=\"token keyword\">not</span> <span class=\"token keyword\">in</span> self<span class=\"token punctuation\">.</span>ranks<span class=\"token punctuation\">.</span>keys<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>  <span class=\"token comment\"># no such entry</span>\r\n                self<span class=\"token punctuation\">.</span>ranks<span class=\"token punctuation\">.</span>update<span class=\"token punctuation\">(</span><span class=\"token punctuation\">{</span>layer<span class=\"token punctuation\">:</span> taylor<span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\r\n            <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\r\n                self<span class=\"token punctuation\">.</span>ranks<span class=\"token punctuation\">[</span>layer<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">.9</span><span class=\"token operator\">*</span>self<span class=\"token punctuation\">.</span>ranks<span class=\"token punctuation\">[</span>layer<span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> <span class=\"token number\">.1</span><span class=\"token operator\">*</span>taylor  <span class=\"token comment\"># C</span>\r\n        self<span class=\"token punctuation\">.</span>clear_cache<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n\r\n    <span class=\"token keyword\">def</span> <span class=\"token function\">_rank_channels</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> prune_channels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n        total_rank <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>  <span class=\"token comment\"># flattened ranks of each channel, all layers</span>\r\n        channel_layers <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>  <span class=\"token comment\"># layer num for each channel</span>\r\n        layer_channels <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>  <span class=\"token comment\"># channel num wrt layer for each channel</span>\r\n        self<span class=\"token punctuation\">.</span>flops<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>x <span class=\"token operator\">/</span> <span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>flops<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> x <span class=\"token keyword\">in</span> self<span class=\"token punctuation\">.</span>flops<span class=\"token punctuation\">]</span>  <span class=\"token comment\"># Normalize FLOPs</span>\r\n        <span class=\"token comment\"># print(self.flops, self.ranks.items())</span>\r\n        <span class=\"token keyword\">for</span> layer<span class=\"token punctuation\">,</span> ranks <span class=\"token keyword\">in</span> self<span class=\"token punctuation\">.</span>ranks<span class=\"token punctuation\">.</span>items<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n            <span class=\"token comment\"># Average across minibatches</span>\r\n            taylor <span class=\"token operator\">=</span> ranks  <span class=\"token comment\"># C</span>\r\n            <span class=\"token comment\"># Layer-wise L2 normalization</span>\r\n            taylor <span class=\"token operator\">=</span> taylor <span class=\"token operator\">/</span> torch<span class=\"token punctuation\">.</span>sqrt<span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>taylor<span class=\"token operator\">**</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># C</span>\r\n            total_rank<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>taylor <span class=\"token operator\">+</span> self<span class=\"token punctuation\">.</span>flops<span class=\"token punctuation\">[</span>layer<span class=\"token punctuation\">]</span><span class=\"token operator\">*</span>self<span class=\"token punctuation\">.</span>flops_reg<span class=\"token punctuation\">)</span>\r\n            channel_layers<span class=\"token punctuation\">.</span>extend<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>layer<span class=\"token punctuation\">]</span><span class=\"token operator\">*</span>ranks<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\r\n            layer_channels<span class=\"token punctuation\">.</span>extend<span class=\"token punctuation\">(</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>ranks<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\n\r\n        channel_layers <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>Tensor<span class=\"token punctuation\">(</span>channel_layers<span class=\"token punctuation\">)</span>\r\n        layer_channels <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>Tensor<span class=\"token punctuation\">(</span>layer_channels<span class=\"token punctuation\">)</span>\r\n        total_rank <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>cat<span class=\"token punctuation\">(</span>total_rank<span class=\"token punctuation\">,</span> dim<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\r\n\r\n        <span class=\"token comment\"># Rank</span>\r\n        sorted_rank<span class=\"token punctuation\">,</span> sorted_indices <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>topk<span class=\"token punctuation\">(</span>total_rank<span class=\"token punctuation\">,</span> prune_channels<span class=\"token punctuation\">,</span> largest<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\r\n        sorted_channel_layers <span class=\"token operator\">=</span> channel_layers<span class=\"token punctuation\">[</span>sorted_indices<span class=\"token punctuation\">]</span>\r\n        sorted_layer_channels <span class=\"token operator\">=</span> layer_channels<span class=\"token punctuation\">[</span>sorted_indices<span class=\"token punctuation\">]</span>\r\n        <span class=\"token keyword\">return</span> sorted_channel_layers<span class=\"token punctuation\">,</span> sorted_layer_channels\r\n\r\n    <span class=\"token keyword\">def</span> <span class=\"token function\">pruning</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> prune_channels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n\r\n        sorted_channel_layers<span class=\"token punctuation\">,</span> sorted_layer_channels <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>_rank_channels<span class=\"token punctuation\">(</span>prune_channels<span class=\"token punctuation\">)</span>\r\n        inchans<span class=\"token punctuation\">,</span> outchans <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>create_indices<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n\r\n        <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>sorted_channel_layers<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n            cl <span class=\"token operator\">=</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>sorted_channel_layers<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\r\n            lc <span class=\"token operator\">=</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>sorted_layer_channels<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\r\n\r\n            <span class=\"token comment\"># These tensors are concat at a later conv2d</span>\r\n            <span class=\"token comment\"># res_prev = {1:16, 3:14, 5:12, 7:10}</span>\r\n            res <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span> <span class=\"token keyword\">if</span> cl <span class=\"token keyword\">in</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">7</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">else</span> <span class=\"token boolean\">False</span>\r\n\r\n            <span class=\"token comment\"># These tensors are concat with an earlier tensor at bottom.</span>\r\n            offset <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span> <span class=\"token keyword\">if</span> cl <span class=\"token keyword\">in</span> <span class=\"token punctuation\">[</span><span class=\"token number\">9</span><span class=\"token punctuation\">,</span> <span class=\"token number\">11</span><span class=\"token punctuation\">,</span> <span class=\"token number\">13</span><span class=\"token punctuation\">,</span> <span class=\"token number\">15</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">else</span> <span class=\"token boolean\">False</span>\r\n\r\n            <span class=\"token comment\"># Remove indices of pruned parameters/channels</span>\r\n            <span class=\"token keyword\">if</span> offset<span class=\"token punctuation\">:</span>\r\n                mapping <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token number\">9</span><span class=\"token punctuation\">:</span> <span class=\"token number\">7</span><span class=\"token punctuation\">,</span> <span class=\"token number\">11</span><span class=\"token punctuation\">:</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">13</span><span class=\"token punctuation\">:</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">15</span><span class=\"token punctuation\">:</span> <span class=\"token number\">1</span><span class=\"token punctuation\">}</span>\r\n                top <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>convs<span class=\"token punctuation\">[</span>mapping<span class=\"token punctuation\">[</span>cl<span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>weight<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\r\n                <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span>\r\n                    inchans<span class=\"token punctuation\">[</span>cl <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>remove<span class=\"token punctuation\">(</span>top <span class=\"token operator\">+</span> lc<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># it is searching for a -ve number to remove, but there are none</span>\r\n                    <span class=\"token comment\"># However, the output channel of the previous layer (d4) is reduced</span>\r\n                    <span class=\"token comment\"># So up1's input channel is larger than expected due to failed removal</span>\r\n                <span class=\"token keyword\">except</span> ValueError<span class=\"token punctuation\">:</span>\r\n                    <span class=\"token keyword\">pass</span>\r\n            <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\r\n                <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span>\r\n                    inchans<span class=\"token punctuation\">[</span>cl <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>remove<span class=\"token punctuation\">(</span>lc<span class=\"token punctuation\">)</span>\r\n                <span class=\"token keyword\">except</span> ValueError<span class=\"token punctuation\">:</span>\r\n                    <span class=\"token keyword\">pass</span>\r\n            <span class=\"token keyword\">if</span> res<span class=\"token punctuation\">:</span>\r\n                <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span>\r\n                    inchans<span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token punctuation\">(</span>cl <span class=\"token operator\">+</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>remove<span class=\"token punctuation\">(</span>lc<span class=\"token punctuation\">)</span>\r\n                <span class=\"token keyword\">except</span> ValueError<span class=\"token punctuation\">:</span>\r\n                    <span class=\"token keyword\">pass</span>\r\n            <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span>\r\n                outchans<span class=\"token punctuation\">[</span>cl<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>remove<span class=\"token punctuation\">(</span>lc<span class=\"token punctuation\">)</span>\r\n            <span class=\"token keyword\">except</span> ValueError<span class=\"token punctuation\">:</span>\r\n                <span class=\"token keyword\">pass</span>\r\n\r\n        <span class=\"token comment\"># Use indexing to get rid of parameters</span>\r\n        <span class=\"token comment\"># print(self.convs, inchans, outchans)</span>\r\n        <span class=\"token keyword\">for</span> i<span class=\"token punctuation\">,</span> c <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>convs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n            self<span class=\"token punctuation\">.</span>convs<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>weight<span class=\"token punctuation\">.</span>data <span class=\"token operator\">=</span> c<span class=\"token punctuation\">.</span>weight<span class=\"token punctuation\">[</span>outchans<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> inchans<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">]</span>\r\n            self<span class=\"token punctuation\">.</span>convs<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>bias <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span>\r\n\r\n        <span class=\"token keyword\">for</span> i<span class=\"token punctuation\">,</span> bn <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>BNs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n            self<span class=\"token punctuation\">.</span>BNs<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>running_mean<span class=\"token punctuation\">.</span>data <span class=\"token operator\">=</span> bn<span class=\"token punctuation\">.</span>running_mean<span class=\"token punctuation\">[</span>outchans<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span>\r\n            self<span class=\"token punctuation\">.</span>BNs<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>running_var<span class=\"token punctuation\">.</span>data <span class=\"token operator\">=</span> bn<span class=\"token punctuation\">.</span>running_var<span class=\"token punctuation\">[</span>outchans<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span>\r\n            self<span class=\"token punctuation\">.</span>BNs<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>weight<span class=\"token punctuation\">.</span>data <span class=\"token operator\">=</span> bn<span class=\"token punctuation\">.</span>weight<span class=\"token punctuation\">[</span>outchans<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span>\r\n            self<span class=\"token punctuation\">.</span>BNs<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>bias <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span>\r\n\r\n    <span class=\"token keyword\">def</span> <span class=\"token function\">create_indices</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n        chans <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>c<span class=\"token punctuation\">.</span>weight<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>c<span class=\"token punctuation\">.</span>weight<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> c <span class=\"token keyword\">in</span> self<span class=\"token punctuation\">.</span>convs<span class=\"token punctuation\">]</span>\r\n        inchans<span class=\"token punctuation\">,</span> outchans <span class=\"token operator\">=</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">zip</span><span class=\"token punctuation\">(</span><span class=\"token operator\">*</span>chans<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\n        <span class=\"token keyword\">return</span> inchans<span class=\"token punctuation\">,</span> outchans\r\n\r\n    <span class=\"token keyword\">def</span> <span class=\"token function\">channel_save</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> path<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n        <span class=\"token triple-quoted-string string\">\"\"\"save the 22 distinct number of channels\"\"\"</span>\r\n        chans <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\r\n        <span class=\"token keyword\">for</span> i<span class=\"token punctuation\">,</span> c <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>convs<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">:</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n            <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>i <span class=\"token operator\">></span> <span class=\"token number\">8</span> <span class=\"token keyword\">and</span> <span class=\"token punctuation\">(</span>i<span class=\"token operator\">-</span><span class=\"token number\">9</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">%</span> <span class=\"token number\">2</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">or</span> i <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\r\n                chans<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>c<span class=\"token punctuation\">.</span>weight<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\r\n            chans<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>c<span class=\"token punctuation\">.</span>weight<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\r\n\r\n        <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>path<span class=\"token punctuation\">,</span> <span class=\"token string\">'w'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> f<span class=\"token punctuation\">:</span>\r\n            <span class=\"token keyword\">for</span> item <span class=\"token keyword\">in</span> chans<span class=\"token punctuation\">:</span>\r\n                f<span class=\"token punctuation\">.</span>write<span class=\"token punctuation\">(</span><span class=\"token string\">\"%s\\n\"</span> <span class=\"token operator\">%</span> item<span class=\"token punctuation\">)</span>\r\n\r\n    <span class=\"token keyword\">def</span> <span class=\"token function\">calc_flops</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n        <span class=\"token triple-quoted-string string\">\"\"\"Calculate flops per tensor channel. Only consider flops\r\n        of conv2d that produces said feature map\r\n        \"\"\"</span>\r\n        <span class=\"token comment\"># conv2d: slides*(kernel mult + kernel sum + bias)</span>\r\n        <span class=\"token comment\"># kernel_sum = kernel_mult - 1</span>\r\n        <span class=\"token comment\"># conv2d: slides*(2*kernel mult)</span>\r\n\r\n        <span class=\"token comment\"># batchnorm2d: 4*slides</span>\r\n\r\n        <span class=\"token comment\"># Remove unnecessary constants from calculation</span>\r\n\r\n        <span class=\"token keyword\">for</span> i<span class=\"token punctuation\">,</span> c <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>convs<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n            H<span class=\"token punctuation\">,</span> W <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>gradients<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span>\r\n            O<span class=\"token punctuation\">,</span> I<span class=\"token punctuation\">,</span> KH<span class=\"token punctuation\">,</span> KW <span class=\"token operator\">=</span> c<span class=\"token punctuation\">.</span>weight<span class=\"token punctuation\">.</span>shape\r\n            self<span class=\"token punctuation\">.</span>flops<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>H<span class=\"token operator\">*</span>W<span class=\"token operator\">*</span>KH<span class=\"token operator\">*</span>KW<span class=\"token operator\">*</span>I<span class=\"token punctuation\">)</span>\r\n        <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>flops\r\n\r\n    <span class=\"token keyword\">def</span> <span class=\"token function\">close</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n        <span class=\"token keyword\">for</span> handle <span class=\"token keyword\">in</span> self<span class=\"token punctuation\">.</span>hook_handler<span class=\"token punctuation\">:</span>\r\n            handle<span class=\"token punctuation\">.</span>remove<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n        <span class=\"token keyword\">return</span></code></pre></div>\n<h3 id=\"剪枝过程\" style=\"position:relative;\">剪枝过程<a href=\"#%E5%89%AA%E6%9E%9D%E8%BF%87%E7%A8%8B\" aria-label=\"剪枝过程 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<p>下面是相应python代码,只表示所需过程,仅供读者参考</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">\t<span class=\"token keyword\">from</span> prune_utils <span class=\"token keyword\">import</span> Pruner\r\n    net <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span><span class=\"token string\">'./model.pth'</span><span class=\"token punctuation\">,</span> map_location<span class=\"token operator\">=</span><span class=\"token string\">'cpu'</span><span class=\"token punctuation\">)</span>\r\n    pruner <span class=\"token operator\">=</span> Pruner<span class=\"token punctuation\">(</span>net<span class=\"token punctuation\">,</span> <span class=\"token number\">.001</span><span class=\"token punctuation\">)</span>\r\n    batch_size <span class=\"token operator\">=</span> <span class=\"token number\">32</span>\r\n    <span class=\"token keyword\">with</span> tqdm<span class=\"token punctuation\">(</span>total<span class=\"token operator\">=</span><span class=\"token number\">10</span> <span class=\"token operator\">*</span> batch_size<span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> progress_bar<span class=\"token punctuation\">:</span>\r\n        <span class=\"token keyword\">for</span> i<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>inputs<span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">)</span> <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>dataloader_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n            masks_pred <span class=\"token operator\">=</span> net<span class=\"token punctuation\">(</span>inputs<span class=\"token punctuation\">)</span>\r\n            loss <span class=\"token operator\">=</span> criterion<span class=\"token punctuation\">(</span>masks_pred<span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">)</span>\r\n            loss<span class=\"token punctuation\">.</span>backward<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n            pruner<span class=\"token punctuation\">.</span>compute_rank<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n            progress_bar<span class=\"token punctuation\">.</span>update<span class=\"token punctuation\">(</span>batch_size<span class=\"token punctuation\">)</span>\r\n            <span class=\"token keyword\">if</span> i <span class=\"token operator\">==</span> <span class=\"token number\">10</span><span class=\"token punctuation\">:</span>\r\n                <span class=\"token keyword\">break</span>\r\n\r\n    pruner<span class=\"token punctuation\">.</span>pruning<span class=\"token punctuation\">(</span><span class=\"token number\">300</span><span class=\"token punctuation\">)</span>\r\n    pruner<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n    torch<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span>net<span class=\"token punctuation\">,</span> <span class=\"token string\">\"pruned_model.pth\"</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h3 id=\"微调fine-tune部分\" style=\"position:relative;\">微调(fine-tune)部分<a href=\"#%E5%BE%AE%E8%B0%83fine-tune%E9%83%A8%E5%88%86\" aria-label=\"微调fine tune部分 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<p>下面是相应python代码,solver中实现了模型训练所需逻辑,暂无法提供源码</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">    net <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span><span class=\"token string\">\"pruned_model.pth\"</span><span class=\"token punctuation\">,</span> map_location<span class=\"token operator\">=</span><span class=\"token string\">'cuda:0'</span><span class=\"token punctuation\">)</span>\r\n    <span class=\"token keyword\">for</span> name<span class=\"token punctuation\">,</span> parameters <span class=\"token keyword\">in</span> net<span class=\"token punctuation\">.</span>named_parameters<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>name<span class=\"token punctuation\">,</span> <span class=\"token string\">':'</span><span class=\"token punctuation\">,</span> parameters<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\n    optimizer <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>optim<span class=\"token punctuation\">.</span>Adam<span class=\"token punctuation\">(</span>net<span class=\"token punctuation\">.</span>parameters<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> lr<span class=\"token operator\">=</span><span class=\"token number\">0.001</span><span class=\"token punctuation\">)</span>\r\n    lr_scheduler <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>optim<span class=\"token punctuation\">.</span>lr_scheduler<span class=\"token punctuation\">.</span>ExponentialLR<span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span>optimizer<span class=\"token punctuation\">,</span> gamma<span class=\"token operator\">=</span><span class=\"token number\">0.95</span><span class=\"token punctuation\">)</span>\r\n\r\n    solver <span class=\"token operator\">=</span> lab<span class=\"token punctuation\">.</span>Solver<span class=\"token punctuation\">(</span>\r\n        model<span class=\"token operator\">=</span>net<span class=\"token punctuation\">,</span>\r\n        optimizer<span class=\"token operator\">=</span>optimizer<span class=\"token punctuation\">,</span>\r\n        criterion<span class=\"token operator\">=</span>MyBinaryCrossEntropy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\r\n        lr_scheduler<span class=\"token operator\">=</span>lr_scheduler\r\n    <span class=\"token punctuation\">)</span>\r\n    solver<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">(</span>\r\n        epochs<span class=\"token operator\">=</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span>\r\n        data_loader<span class=\"token operator\">=</span>dataloader_train<span class=\"token punctuation\">,</span>\r\n        val_loader<span class=\"token operator\">=</span>dataloader_val<span class=\"token punctuation\">,</span>\r\n        save_path<span class=\"token operator\">=</span><span class=\"token string\">'./model_finetune.pth'</span><span class=\"token punctuation\">,</span>\r\n        img_name<span class=\"token operator\">=</span><span class=\"token string\">'model_finetune'</span><span class=\"token punctuation\">,</span>\r\n    <span class=\"token punctuation\">)</span></code></pre></div>\n<h3 id=\"剪枝效果\" style=\"position:relative;\">剪枝效果<a href=\"#%E5%89%AA%E6%9E%9D%E6%95%88%E6%9E%9C\" aria-label=\"剪枝效果 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> thop <span class=\"token keyword\">import</span> profile\r\ndevice <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>device<span class=\"token punctuation\">(</span><span class=\"token string\">'cuda'</span> <span class=\"token keyword\">if</span> torch<span class=\"token punctuation\">.</span>cuda<span class=\"token punctuation\">.</span>is_available<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">else</span> <span class=\"token string\">'cpu'</span><span class=\"token punctuation\">)</span>\r\noptimizer <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>optim<span class=\"token punctuation\">.</span>Adam<span class=\"token punctuation\">(</span>net<span class=\"token punctuation\">.</span>parameters<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> lr<span class=\"token operator\">=</span><span class=\"token number\">0.01</span><span class=\"token punctuation\">)</span>\r\nlr_scheduler <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>optim<span class=\"token punctuation\">.</span>lr_scheduler<span class=\"token punctuation\">.</span>ExponentialLR<span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span>optimizer<span class=\"token punctuation\">,</span> gamma<span class=\"token operator\">=</span><span class=\"token number\">0.99</span><span class=\"token punctuation\">)</span>\r\nnet <span class=\"token operator\">=</span>  torch<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span><span class=\"token string\">\"./model_finetune.pth\"</span><span class=\"token punctuation\">)</span>\r\nnet <span class=\"token operator\">=</span> net<span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span>\r\ndataiter <span class=\"token operator\">=</span> <span class=\"token builtin\">iter</span><span class=\"token punctuation\">(</span>dataloader_test<span class=\"token punctuation\">)</span>\r\nimages<span class=\"token punctuation\">,</span> labels <span class=\"token operator\">=</span> <span class=\"token builtin\">next</span><span class=\"token punctuation\">(</span>dataiter<span class=\"token punctuation\">)</span>\r\nimages <span class=\"token operator\">=</span> images<span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span>\r\nlabels <span class=\"token operator\">=</span> labels<span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span>\r\nflops<span class=\"token punctuation\">,</span> params <span class=\"token operator\">=</span> profile<span class=\"token punctuation\">(</span>net<span class=\"token punctuation\">,</span> inputs<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>images<span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'FLOPs: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>flops<span class=\"token punctuation\">}</span></span><span class=\"token string\">, Params: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>params<span class=\"token punctuation\">}</span></span><span class=\"token string\">'</span></span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>发现剪枝效果如下表所示</p>\n<table>\n<thead>\n<tr>\n<th>模型类型</th>\n<th>FLOPs</th>\n<th>Params</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>初始模型</td>\n<td>250408337408.0</td>\n<td>3349763.0</td>\n</tr>\n<tr>\n<td>一次剪枝</td>\n<td>188382691328.0</td>\n<td>2425639.0</td>\n</tr>\n<tr>\n<td>两次剪枝</td>\n<td>147422117888.0</td>\n<td>1594948.0</td>\n</tr>\n<tr>\n<td>三次剪枝</td>\n<td>105292963840.0</td>\n<td>921094.0</td>\n</tr>\n</tbody>\n</table>\n<p>但是三次剪枝并微调后效果不理想,因此使用两次剪枝的结果移植到rk3588上部署</p>\n<h3 id=\"参考\" style=\"position:relative;\">参考<a href=\"#%E5%8F%82%E8%80%83\" aria-label=\"参考 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<p>剪枝代码基于: <a href=\"https://github.com/pachiko/Prune_U-Net\">https://github.com/pachiko/Prune_U-Net</a>\r\n剪枝思路基于论文: Pruning Convolutional Neural Networks for Resource Efficient Inference</p>\n<h2 id=\"部署到rk3588开发板\" style=\"position:relative;\">部署到rk3588开发板<a href=\"#%E9%83%A8%E7%BD%B2%E5%88%B0rk3588%E5%BC%80%E5%8F%91%E6%9D%BF\" aria-label=\"部署到rk3588开发板 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h2>\n<h3 id=\"pth模型转化为onnx模型\" style=\"position:relative;\">pth模型转化为onnx模型<a href=\"#pth%E6%A8%A1%E5%9E%8B%E8%BD%AC%E5%8C%96%E4%B8%BAonnx%E6%A8%A1%E5%9E%8B\" aria-label=\"pth模型转化为onnx模型 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> torch\r\n<span class=\"token keyword\">from</span> torch <span class=\"token keyword\">import</span> nn\r\n<span class=\"token keyword\">import</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>functional <span class=\"token keyword\">as</span> F\r\n\r\n\r\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">DoubleConv</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> in_channels<span class=\"token punctuation\">,</span> out_channels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span>DoubleConv<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n        self<span class=\"token punctuation\">.</span>conv <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\r\n            nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token punctuation\">,</span> out_channels<span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\r\n            nn<span class=\"token punctuation\">.</span>BatchNorm2d<span class=\"token punctuation\">(</span>out_channels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\r\n            nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span>inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\r\n            nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>out_channels<span class=\"token punctuation\">,</span> out_channels<span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\r\n            nn<span class=\"token punctuation\">.</span>BatchNorm2d<span class=\"token punctuation\">(</span>out_channels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\r\n            nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span>inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\r\n        <span class=\"token punctuation\">)</span>\r\n\r\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n        <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>conv<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\r\n\r\n\r\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Down</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> in_channels<span class=\"token punctuation\">,</span> out_channels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span>Down<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n        self<span class=\"token punctuation\">.</span>mpconv <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span>\r\n            nn<span class=\"token punctuation\">.</span>MaxPool2d<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\r\n            DoubleConv<span class=\"token punctuation\">(</span>in_channels<span class=\"token punctuation\">,</span> out_channels<span class=\"token punctuation\">)</span>\r\n        <span class=\"token punctuation\">)</span>\r\n\r\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n        <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>mpconv<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\r\n\r\n\r\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Up</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> in_channels<span class=\"token punctuation\">,</span> out_channels<span class=\"token punctuation\">,</span> bilinear<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span>Up<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n\r\n        <span class=\"token keyword\">if</span> bilinear<span class=\"token punctuation\">:</span>\r\n            self<span class=\"token punctuation\">.</span>up <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Upsample<span class=\"token punctuation\">(</span>scale_factor<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> mode<span class=\"token operator\">=</span><span class=\"token string\">'bilinear'</span><span class=\"token punctuation\">,</span> align_corners<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\r\n        <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\r\n            self<span class=\"token punctuation\">.</span>up <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>ConvTranspose2d<span class=\"token punctuation\">(</span>in_channels <span class=\"token operator\">//</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> in_channels <span class=\"token operator\">//</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\r\n\r\n        self<span class=\"token punctuation\">.</span>conv <span class=\"token operator\">=</span> DoubleConv<span class=\"token punctuation\">(</span>in_channels<span class=\"token punctuation\">,</span> out_channels<span class=\"token punctuation\">)</span>\r\n\r\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x1<span class=\"token punctuation\">,</span> x2<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n        x1 <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>up<span class=\"token punctuation\">(</span>x1<span class=\"token punctuation\">)</span>\r\n        diffY <span class=\"token operator\">=</span> x2<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">-</span> x1<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span>\r\n        diffX <span class=\"token operator\">=</span> x2<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">-</span> x1<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">]</span>\r\n\r\n        x1 <span class=\"token operator\">=</span> F<span class=\"token punctuation\">.</span>pad<span class=\"token punctuation\">(</span>x1<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span>diffX <span class=\"token operator\">//</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> diffX <span class=\"token operator\">-</span> diffX <span class=\"token operator\">//</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span>\r\n                        diffY <span class=\"token operator\">//</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> diffY <span class=\"token operator\">-</span> diffY <span class=\"token operator\">//</span> <span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\r\n        x <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>cat<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>x2<span class=\"token punctuation\">,</span> x1<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> dim<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\r\n        <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>conv<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\r\n\r\n\r\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">UNet</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> n_channels<span class=\"token punctuation\">,</span> n_classes<span class=\"token punctuation\">,</span> bilinear<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> C_base<span class=\"token operator\">=</span><span class=\"token number\">64</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span>UNet<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n        self<span class=\"token punctuation\">.</span>n_channels <span class=\"token operator\">=</span> n_channels\r\n        self<span class=\"token punctuation\">.</span>n_classes <span class=\"token operator\">=</span> n_classes\r\n        self<span class=\"token punctuation\">.</span>bilinear <span class=\"token operator\">=</span> bilinear\r\n        self<span class=\"token punctuation\">.</span>C_base <span class=\"token operator\">=</span> C_base\r\n\r\n        self<span class=\"token punctuation\">.</span>inc <span class=\"token operator\">=</span> DoubleConv<span class=\"token punctuation\">(</span>n_channels<span class=\"token punctuation\">,</span> C_base<span class=\"token punctuation\">)</span>\r\n        self<span class=\"token punctuation\">.</span>down1 <span class=\"token operator\">=</span> Down<span class=\"token punctuation\">(</span>C_base<span class=\"token punctuation\">,</span> C_base <span class=\"token operator\">*</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\r\n        self<span class=\"token punctuation\">.</span>down2 <span class=\"token operator\">=</span> Down<span class=\"token punctuation\">(</span>C_base <span class=\"token operator\">*</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> C_base <span class=\"token operator\">*</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span>\r\n        self<span class=\"token punctuation\">.</span>down3 <span class=\"token operator\">=</span> Down<span class=\"token punctuation\">(</span>C_base <span class=\"token operator\">*</span> <span class=\"token number\">4</span><span class=\"token punctuation\">,</span> C_base <span class=\"token operator\">*</span> <span class=\"token number\">8</span><span class=\"token punctuation\">)</span>\r\n        self<span class=\"token punctuation\">.</span>down4 <span class=\"token operator\">=</span> Down<span class=\"token punctuation\">(</span>C_base <span class=\"token operator\">*</span> <span class=\"token number\">8</span><span class=\"token punctuation\">,</span> C_base <span class=\"token operator\">*</span> <span class=\"token number\">8</span><span class=\"token punctuation\">)</span>\r\n        self<span class=\"token punctuation\">.</span>up1 <span class=\"token operator\">=</span> Up<span class=\"token punctuation\">(</span>C_base <span class=\"token operator\">*</span> <span class=\"token number\">16</span><span class=\"token punctuation\">,</span> C_base <span class=\"token operator\">*</span> <span class=\"token number\">4</span><span class=\"token punctuation\">,</span> bilinear<span class=\"token punctuation\">)</span>\r\n        self<span class=\"token punctuation\">.</span>up2 <span class=\"token operator\">=</span> Up<span class=\"token punctuation\">(</span>C_base <span class=\"token operator\">*</span> <span class=\"token number\">8</span><span class=\"token punctuation\">,</span> C_base <span class=\"token operator\">*</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> bilinear<span class=\"token punctuation\">)</span>\r\n        self<span class=\"token punctuation\">.</span>up3 <span class=\"token operator\">=</span> Up<span class=\"token punctuation\">(</span>C_base <span class=\"token operator\">*</span> <span class=\"token number\">4</span><span class=\"token punctuation\">,</span> C_base<span class=\"token punctuation\">,</span> bilinear<span class=\"token punctuation\">)</span>\r\n        self<span class=\"token punctuation\">.</span>up4 <span class=\"token operator\">=</span> Up<span class=\"token punctuation\">(</span>C_base <span class=\"token operator\">*</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> C_base<span class=\"token punctuation\">,</span> bilinear<span class=\"token punctuation\">)</span>\r\n        self<span class=\"token punctuation\">.</span>outc <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>C_base<span class=\"token punctuation\">,</span> n_classes<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\r\n\r\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n        x1 <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>inc<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\r\n        x2 <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>down1<span class=\"token punctuation\">(</span>x1<span class=\"token punctuation\">)</span>\r\n        x3 <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>down2<span class=\"token punctuation\">(</span>x2<span class=\"token punctuation\">)</span>\r\n        x4 <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>down3<span class=\"token punctuation\">(</span>x3<span class=\"token punctuation\">)</span>\r\n        x5 <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>down4<span class=\"token punctuation\">(</span>x4<span class=\"token punctuation\">)</span>\r\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>up1<span class=\"token punctuation\">(</span>x5<span class=\"token punctuation\">,</span> x4<span class=\"token punctuation\">)</span>\r\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>up2<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> x3<span class=\"token punctuation\">)</span>\r\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>up3<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> x2<span class=\"token punctuation\">)</span>\r\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>up4<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> x1<span class=\"token punctuation\">)</span>\r\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>outc<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\r\n        <span class=\"token keyword\">return</span> x\r\n\r\nmodel <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span><span class=\"token string\">\"model_finetune.pth\"</span><span class=\"token punctuation\">,</span> map_location<span class=\"token operator\">=</span><span class=\"token string\">\"cpu\"</span><span class=\"token punctuation\">)</span>\r\nnet<span class=\"token operator\">=</span>model<span class=\"token punctuation\">.</span><span class=\"token builtin\">eval</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\nexample<span class=\"token operator\">=</span>torch<span class=\"token punctuation\">.</span>rand<span class=\"token punctuation\">(</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">256</span><span class=\"token punctuation\">,</span> <span class=\"token number\">256</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">#给定输入</span>\r\ntorch<span class=\"token punctuation\">.</span>onnx<span class=\"token punctuation\">.</span>export<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">,</span><span class=\"token punctuation\">(</span>example<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token string\">'./model_finetune2.onnx'</span><span class=\"token punctuation\">,</span>verbose<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> opset_version<span class=\"token operator\">=</span><span class=\"token number\">17</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">#导出</span></code></pre></div>\n<p>注意,虽然我们存储的是完整的模型,但是依旧需要定义原本的UNet模型,并且需要指定map_location以使得模型加载到cpu上</p>\n<h3 id=\"部署到开发板\" style=\"position:relative;\">部署到开发板<a href=\"#%E9%83%A8%E7%BD%B2%E5%88%B0%E5%BC%80%E5%8F%91%E6%9D%BF\" aria-label=\"部署到开发板 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<p>onnx转化为rknn与在开发板上运行的代码已经在上篇文章中写得很详尽了,因而直接放效果图:</p>\n<ul>\n<li>剪枝后</li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/5f9382d397c117f6871933e169120932/45662/img.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 58.22784810126582%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAIAAADtbgqsAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB80lEQVR42mP4/+8/Jvr39x8QYZH6j8JlgFB///wDon8Q8u//j++v/vr5DSj+BywINuv/z+9vPr6/DVb/D0UzHADNAZIPX+35+fMzmuCnb49evDsD4iI0A5Vef9yVNLk3dVpzdHdLXG9v4vTWxpYPn96vm7i1Lbq/Pb6/JrS1J2laQ2rb1t2bger//vmL0Hx673lTBldLBg9jRm9zJm9TBhdn2+h3H98XedboMNhaMfuYMvpYM3hpsThMnbMUqP7P7z8Izef3X3ZmCnJlDE3W9wtXCXZkCHK1Snv97l2tb5sVg7cvX0iEeqAXW7gpq9/EaSvAmpFsPrfvkjODvzVL1KyjAXVZ3uYMgW6m6W/eva/xbTVm8IwNip+7zdeVLcyYwWfK1DXoNgM1OzD4OnCGGptk2vFGODD4uOoANX+o9GoxZ3C1V0ixUkx1ZQgyZvCe1LMS3ebz+y45AW1jDnFnDHBjCXFiCPBSS3/z5n21T6sVg5cHS7AbY6AHa5gZg+/MnrUgzb+QbP766dvNM7dvnb1z8/zdm2fv3Lt4f+3CvZ8+fnl+78X1U7duAQXP3bl/6f7hraeP7b8Iiqo/uOL5L4hzcu8FoIkIwX8gwecPX10/exeqBlnzP0hKAiNgivj07vOvn7+QxYGCP7/9/PrpK3IKBQCYpxwjadzJsAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img.png\"\n        title=\"\"\n        src=\"/static/5f9382d397c117f6871933e169120932/f058b/img.png\"\n        srcset=\"/static/5f9382d397c117f6871933e169120932/c26ae/img.png 158w,\n/static/5f9382d397c117f6871933e169120932/6bdcf/img.png 315w,\n/static/5f9382d397c117f6871933e169120932/f058b/img.png 630w,\n/static/5f9382d397c117f6871933e169120932/40601/img.png 945w,\n/static/5f9382d397c117f6871933e169120932/78612/img.png 1260w,\n/static/5f9382d397c117f6871933e169120932/45662/img.png 1410w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<ul>\n<li>原模型</li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/51d98e1c2e0a837e3e235d4bb5ba18e9/92338/img_1.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 48.734177215189874%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAIAAAA7N+mxAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB4klEQVR42mP4/+8/CKGC3z/f/fzxFV303+/v317/+f0PquXffwYg/vf33++fv//8+vPpw6eP7z/8//P/2asDHz8+/f8XaMrv71+/v3rx6tuXnz++v3368iBQ8P+/fzDN//8/uf0sSTcvSTsvQSsnQSs7Sb0gwTvx4ZMHa/o2h0olJevlx2lkJmnmx+qkdTa3/fnxF+SKvzDN9648tGPytWfwMWcMMGcKADFUA24/eDCzbIEeg50jS4AZQ6A9g78pg3t2dsO/nyDN/+Ca71995M4WYs8QWuLpWejj48gQaq4UdfPew3mVS0wY3Lx4wkpDvfxFQi0YAjLS2v7/+oNiM1CzG3OQJUNkxZLY2mp/O4ZgC5mom7cfzq1aYszg7Kmb3L81KkA+1JzBPyux4/9vVGffv/LIhTHImSnIWCTRkjXClSHAUjjy5s2HcyoWGzM4OfPFmPAkOzOGWDH4ZUe0/f+NavPjm0/D5VLCpVOiJJMiZVIipFN8ldLv3Hi0vH2NB2d4lFxalFRSlFyqn2hCZUI/NKj/wqLq75+/Xz9+BaFP3758+PL7x69DW888e/QSKP7l/RegIBD9+Prj+cNXh3ecAYfWP0Q8IyeSf2D22xfvvn7+hpFyfr9+9hbu5v///gMA0H6lmUyhACEAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img_1.png\"\n        title=\"\"\n        src=\"/static/51d98e1c2e0a837e3e235d4bb5ba18e9/f058b/img_1.png\"\n        srcset=\"/static/51d98e1c2e0a837e3e235d4bb5ba18e9/c26ae/img_1.png 158w,\n/static/51d98e1c2e0a837e3e235d4bb5ba18e9/6bdcf/img_1.png 315w,\n/static/51d98e1c2e0a837e3e235d4bb5ba18e9/f058b/img_1.png 630w,\n/static/51d98e1c2e0a837e3e235d4bb5ba18e9/40601/img_1.png 945w,\n/static/51d98e1c2e0a837e3e235d4bb5ba18e9/78612/img_1.png 1260w,\n/static/51d98e1c2e0a837e3e235d4bb5ba18e9/92338/img_1.png 1411w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span>\r\n运行速度及参数对比如下图:</p>\n<table>\n<thead>\n<tr>\n<th>模型类型</th>\n<th>FLOPs</th>\n<th>Params</th>\n<th>运行速度(ms/张)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>初始模型</td>\n<td>250408337408.0</td>\n<td>3349763.0</td>\n<td>120.7</td>\n</tr>\n<tr>\n<td>两次剪枝</td>\n<td>147422117888.0</td>\n<td>1594948.0</td>\n<td>81.6</td>\n</tr>\n</tbody>\n</table>\n<p>可以观察到,虽然FLOPs降低了44%左右,但是运行速度只降低了32%左右,这是为什么呢?</p>\n<h3 id=\"观察与反思\" style=\"position:relative;\">观察与反思<a href=\"#%E8%A7%82%E5%AF%9F%E4%B8%8E%E5%8F%8D%E6%80%9D\" aria-label=\"观察与反思 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<p>下表是剪枝后模型各层weight的size</p>\n<table>\n<thead>\n<tr>\n<th>层名</th>\n<th>size</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>inc.conv.0.weight</td>\n<td>torch.Size([32, 1, 3, 3])</td>\n</tr>\n<tr>\n<td>inc.conv.1.weight</td>\n<td>torch.Size([32])</td>\n</tr>\n<tr>\n<td>inc.conv.3.weight</td>\n<td>torch.Size([32, 32, 3, 3])</td>\n</tr>\n<tr>\n<td>inc.conv.4.weight</td>\n<td>torch.Size([32])</td>\n</tr>\n<tr>\n<td>down1.mpconv.1.conv.0.weight</td>\n<td>torch.Size([44, 32, 3, 3])</td>\n</tr>\n<tr>\n<td>down1.mpconv.1.conv.1.weight</td>\n<td>torch.Size([44])</td>\n</tr>\n<tr>\n<td>down1.mpconv.1.conv.3.weight</td>\n<td>torch.Size([47, 44, 3, 3])</td>\n</tr>\n<tr>\n<td>down1.mpconv.1.conv.4.weight</td>\n<td>torch.Size([47])</td>\n</tr>\n<tr>\n<td>down2.mpconv.1.conv.0.weight</td>\n<td>torch.Size([88, 47, 3, 3])</td>\n</tr>\n<tr>\n<td>down2.mpconv.1.conv.1.weight</td>\n<td>torch.Size([88])</td>\n</tr>\n<tr>\n<td>down2.mpconv.1.conv.3.weight</td>\n<td>torch.Size([70, 88, 3, 3])</td>\n</tr>\n<tr>\n<td>down2.mpconv.1.conv.4.weight</td>\n<td>torch.Size([70])</td>\n</tr>\n<tr>\n<td>down3.mpconv.1.conv.0.weight</td>\n<td>torch.Size([153, 70, 3, 3])</td>\n</tr>\n<tr>\n<td>down3.mpconv.1.conv.1.weight</td>\n<td>torch.Size([153])</td>\n</tr>\n<tr>\n<td>down3.mpconv.1.conv.3.weight</td>\n<td>torch.Size([139, 153, 3, 3])</td>\n</tr>\n<tr>\n<td>down3.mpconv.1.conv.4.weight</td>\n<td>torch.Size([139])</td>\n</tr>\n<tr>\n<td>down4.mpconv.1.conv.0.weight</td>\n<td>torch.Size([119, 139, 3, 3])</td>\n</tr>\n<tr>\n<td>down4.mpconv.1.conv.1.weight</td>\n<td>torch.Size([119])</td>\n</tr>\n<tr>\n<td>down4.mpconv.1.conv.3.weight</td>\n<td>torch.Size([92, 119, 3, 3])</td>\n</tr>\n<tr>\n<td>down4.mpconv.1.conv.4.weight</td>\n<td>torch.Size([92])</td>\n</tr>\n<tr>\n<td>up1.conv.conv.0.weight</td>\n<td>torch.Size([62, 231, 3, 3])</td>\n</tr>\n<tr>\n<td>up1.conv.conv.1.weight</td>\n<td>torch.Size([62])</td>\n</tr>\n<tr>\n<td>up1.conv.conv.3.weight</td>\n<td>torch.Size([59, 62, 3, 3])</td>\n</tr>\n<tr>\n<td>up1.conv.conv.4.weight</td>\n<td>torch.Size([59])</td>\n</tr>\n<tr>\n<td>up2.conv.conv.0.weight</td>\n<td>torch.Size([44, 129, 3, 3])</td>\n</tr>\n<tr>\n<td>up2.conv.conv.1.weight</td>\n<td>torch.Size([44])</td>\n</tr>\n<tr>\n<td>up2.conv.conv.3.weight</td>\n<td>torch.Size([41, 44, 3, 3])</td>\n</tr>\n<tr>\n<td>up2.conv.conv.4.weight</td>\n<td>torch.Size([41])</td>\n</tr>\n<tr>\n<td>up3.conv.conv.0.weight</td>\n<td>torch.Size([12, 88, 3, 3])</td>\n</tr>\n<tr>\n<td>up3.conv.conv.1.weight</td>\n<td>torch.Size([12])</td>\n</tr>\n<tr>\n<td>up3.conv.conv.3.weight</td>\n<td>torch.Size([14, 12, 3, 3])</td>\n</tr>\n<tr>\n<td>up3.conv.conv.4.weight</td>\n<td>torch.Size([14])</td>\n</tr>\n<tr>\n<td>up4.conv.conv.0.weight</td>\n<td>torch.Size([20, 46, 3, 3])</td>\n</tr>\n<tr>\n<td>up4.conv.conv.1.weight</td>\n<td>torch.Size([20])</td>\n</tr>\n<tr>\n<td>up4.conv.conv.3.weight</td>\n<td>torch.Size([16, 20, 3, 3])</td>\n</tr>\n<tr>\n<td>up4.conv.conv.4.weight</td>\n<td>torch.Size([16])</td>\n</tr>\n</tbody>\n</table>\n<p>可以看到,剪枝后各层size的数字呈现杂乱无序的特点,总参数量虽然降低了,但是结构相比之前不适应于硬件架构,导致运行速度降低幅度相对较小</p>\n<h3 id=\"参考-1\" style=\"position:relative;\">参考<a href=\"#%E5%8F%82%E8%80%83-1\" aria-label=\"参考 1 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<p>南京大学结构化剪枝综述: <a href=\"https://cs.nju.edu.cn/wujx/paper/Pruning_Survey_MLA21.pdf\">https://cs.nju.edu.cn/wujx/paper/Pruning_Survey_MLA21.pdf</a></p>","tableOfContents":"<ul>\n<li>\n<p><a href=\"#%E6%A8%A1%E5%9E%8B%E5%89%AA%E6%9E%9D\">模型剪枝</a></p>\n<ul>\n<li><a href=\"#%E5%89%AA%E6%9E%9D%E6%89%80%E9%9C%80%E5%B7%A5%E5%85%B7%E5%9E%8B%E4%BB%A3%E7%A0%81\">剪枝所需工具型代码</a></li>\n<li><a href=\"#%E5%89%AA%E6%9E%9D%E8%BF%87%E7%A8%8B\">剪枝过程</a></li>\n<li><a href=\"#%E5%BE%AE%E8%B0%83fine-tune%E9%83%A8%E5%88%86\">微调(fine-tune)部分</a></li>\n<li><a href=\"#%E5%89%AA%E6%9E%9D%E6%95%88%E6%9E%9C\">剪枝效果</a></li>\n<li><a href=\"#%E5%8F%82%E8%80%83\">参考</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#%E9%83%A8%E7%BD%B2%E5%88%B0rk3588%E5%BC%80%E5%8F%91%E6%9D%BF\">部署到rk3588开发板</a></p>\n<ul>\n<li><a href=\"#pth%E6%A8%A1%E5%9E%8B%E8%BD%AC%E5%8C%96%E4%B8%BAonnx%E6%A8%A1%E5%9E%8B\">pth模型转化为onnx模型</a></li>\n<li><a href=\"#%E9%83%A8%E7%BD%B2%E5%88%B0%E5%BC%80%E5%8F%91%E6%9D%BF\">部署到开发板</a></li>\n<li><a href=\"#%E8%A7%82%E5%AF%9F%E4%B8%8E%E5%8F%8D%E6%80%9D\">观察与反思</a></li>\n<li><a href=\"#%E5%8F%82%E8%80%83-1\">参考</a></li>\n</ul>\n</li>\n</ul>","headings":[{"value":"模型剪枝","depth":2},{"value":"剪枝所需工具型代码","depth":3},{"value":"剪枝过程","depth":3},{"value":"微调(fine-tune)部分","depth":3},{"value":"剪枝效果","depth":3},{"value":"参考","depth":3},{"value":"部署到rk3588开发板","depth":2},{"value":"pth模型转化为onnx模型","depth":3},{"value":"部署到开发板","depth":3},{"value":"观察与反思","depth":3},{"value":"参考","depth":3}],"frontmatter":{"title":"从UNet模型剪枝到rk3588板端推理部署","date":"June 10, 2024","description":"对UNet模型进行剪枝,提升推理速度"}},"previous":{"fields":{"slug":"/MX6ULL-dw1000/"},"frontmatter":{"title":"正点原子I.MX6ULL mini适配xueliu dw1000驱动"}},"next":{"fields":{"slug":"/robotics-pybullet/"},"frontmatter":{"title":"南科大高等机器人控制课程总结与project"}}},"pageContext":{"id":"8293b5a4-1d1e-5da0-bdf1-d580a1746b0c","previousPostId":"c496b3a2-1cb2-56e5-9bf1-824226faf695","nextPostId":"3e7ff1e3-77d5-5cb8-b1ff-553794a1b0b6"}},"staticQueryHashes":["230163734","2841359383"],"slicesMap":{}}